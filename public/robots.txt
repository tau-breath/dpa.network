# robots.txt for DPA - Decentralized Protection Alliance
# https://dpa.network

User-agent: *
Allow: /

# Disallow sensitive paths (if any)
# Disallow: /admin/
# Disallow: /private/

# Sitemap location
Sitemap: https://dpa.network/sitemap.xml

# Crawl-delay (optional, helps with server load)
Crawl-delay: 0.5

# Specific bot rules
User-agent: Googlebot
Allow: /

User-agent: Googlebot-Image
Allow: /

User-agent: Googlebot-Mobile
Allow: /

User-agent: Googlebot-News
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

User-agent: NaverBot
Allow: /

# Block bad bots
User-agent: MJ12bot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Crawl-delay: 5

# Host declaration (optional, but good for clarity)
Host: https://dpa.network
